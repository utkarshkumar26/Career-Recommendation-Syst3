{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd1f59e5-26b6-4e9d-a562-acc6b91e0f1c",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88f360f2-0318-4073-b032-3e815e70270b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>gender</th>\n",
       "      <th>part_time_job</th>\n",
       "      <th>absence_days</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>weekly_self_study_hours</th>\n",
       "      <th>career_aspiration</th>\n",
       "      <th>math_score</th>\n",
       "      <th>history_score</th>\n",
       "      <th>physics_score</th>\n",
       "      <th>chemistry_score</th>\n",
       "      <th>biology_score</th>\n",
       "      <th>english_score</th>\n",
       "      <th>geography_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Paul</td>\n",
       "      <td>Casey</td>\n",
       "      <td>paul.casey.1@gslingacademy.com</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Danielle</td>\n",
       "      <td>Sandoval</td>\n",
       "      <td>danielle.sandoval.2@gslingacademy.com</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>47</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tina</td>\n",
       "      <td>Andrews</td>\n",
       "      <td>tina.andrews.3@gslingacademy.com</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>Government Officer</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tara</td>\n",
       "      <td>Clark</td>\n",
       "      <td>tara.clark.4@gslingacademy.com</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>Artist</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Anthony</td>\n",
       "      <td>Campos</td>\n",
       "      <td>anthony.campos.5@gslingacademy.com</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>Machanical Engineer</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id first_name last_name                                  email  gender  \\\n",
       "0   1       Paul     Casey         paul.casey.1@gslingacademy.com    male   \n",
       "1   2   Danielle  Sandoval  danielle.sandoval.2@gslingacademy.com  female   \n",
       "2   3       Tina   Andrews       tina.andrews.3@gslingacademy.com  female   \n",
       "3   4       Tara     Clark         tara.clark.4@gslingacademy.com  female   \n",
       "4   5    Anthony    Campos     anthony.campos.5@gslingacademy.com    male   \n",
       "\n",
       "   part_time_job  absence_days  extracurricular_activities  \\\n",
       "0          False             3                       False   \n",
       "1          False             2                       False   \n",
       "2          False             9                        True   \n",
       "3          False             5                       False   \n",
       "4          False             5                       False   \n",
       "\n",
       "   weekly_self_study_hours    career_aspiration  math_score  history_score  \\\n",
       "0                       27               Lawyer          73             81   \n",
       "1                       47               Doctor          90             86   \n",
       "2                       13   Government Officer          81             97   \n",
       "3                        3               Artist          71             74   \n",
       "4                       10  Machanical Engineer          84             77   \n",
       "\n",
       "   physics_score  chemistry_score  biology_score  english_score  \\\n",
       "0             93               97             63             80   \n",
       "1             96              100             90             88   \n",
       "2             95               96             65             77   \n",
       "3             88               80             89             63   \n",
       "4             65               65             80             74   \n",
       "\n",
       "   geography_score  \n",
       "0               87  \n",
       "1               90  \n",
       "2               94  \n",
       "3               86  \n",
       "4               76  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"student-scores.csv\")\n",
    "df= df1.copy()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f18bd17-e5b6-4521-82c6-8b5d5b43bf47",
   "metadata": {},
   "source": [
    "## checking the null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40103930-8229-41a3-9dfe-c648bcc0733a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                            0\n",
       "first_name                    0\n",
       "last_name                     0\n",
       "email                         0\n",
       "gender                        0\n",
       "part_time_job                 0\n",
       "absence_days                  0\n",
       "extracurricular_activities    0\n",
       "weekly_self_study_hours       0\n",
       "career_aspiration             0\n",
       "math_score                    0\n",
       "history_score                 0\n",
       "physics_score                 0\n",
       "chemistry_score               0\n",
       "biology_score                 0\n",
       "english_score                 0\n",
       "geography_score               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda0e449-feab-427e-8619-1ec994948e05",
   "metadata": {},
   "source": [
    "## drop irrelevent columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cccc1670-92b3-4f09-84ce-ac6bf61ce6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['id','first_name','last_name','email'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8af063-272c-425b-9bf9-3bcfaaf42050",
   "metadata": {},
   "source": [
    "## create new feature from all score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8576d198-f4f5-422c-a421-b8c3f0852988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>part_time_job</th>\n",
       "      <th>absence_days</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>weekly_self_study_hours</th>\n",
       "      <th>career_aspiration</th>\n",
       "      <th>math_score</th>\n",
       "      <th>history_score</th>\n",
       "      <th>physics_score</th>\n",
       "      <th>chemistry_score</th>\n",
       "      <th>biology_score</th>\n",
       "      <th>english_score</th>\n",
       "      <th>geography_score</th>\n",
       "      <th>total_score</th>\n",
       "      <th>average_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>574</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>47</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "      <td>640</td>\n",
       "      <td>91.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  part_time_job  absence_days  extracurricular_activities  \\\n",
       "0    male          False             3                       False   \n",
       "1  female          False             2                       False   \n",
       "\n",
       "   weekly_self_study_hours career_aspiration  math_score  history_score  \\\n",
       "0                       27            Lawyer          73             81   \n",
       "1                       47            Doctor          90             86   \n",
       "\n",
       "   physics_score  chemistry_score  biology_score  english_score  \\\n",
       "0             93               97             63             80   \n",
       "1             96              100             90             88   \n",
       "\n",
       "   geography_score  total_score  average_score  \n",
       "0               87          574      82.000000  \n",
       "1               90          640      91.428571  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"total_score\"] = df[\"math_score\"] + df[\"history_score\"] + df[\"physics_score\"] + df[\"chemistry_score\"] + df[\"biology_score\"] + df[\"english_score\"] + df[\"geography_score\"]\n",
    "df[\"average_score\"] = df[\"total_score\"] / 7\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326f6e0e-6192-4481-8a87-bb9c4a97e0d4",
   "metadata": {},
   "source": [
    "## Encoding Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82895b74-a68a-4fc7-ae34-4e872f943c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# # Create a LabelEncoder object\n",
    "# label_encoder = LabelEncoder()\n",
    "\n",
    "# # Encode categorical columns using label encoder\n",
    "# df['gender'] = label_encoder.fit_transform(df['gender'])\n",
    "# df['part_time_job'] = label_encoder.fit_transform(df['part_time_job'])\n",
    "\n",
    "# Define mapping dictionaries for categorical features\n",
    "gender_map = {'male': 0, 'female': 1}\n",
    "part_time_job_map = {False: 0, True: 1}\n",
    "extracurricular_activities_map = {False: 0, True: 1}\n",
    "career_aspiration_map = {\n",
    "        'Lawyer': 0, 'Doctor': 1, 'Government Officer': 2, 'Artist': 3, 'Machanical Engineer': 4,\n",
    "        'Software Engineer': 5, 'Teacher': 6, 'Business Owner': 7, 'Scientist': 8,\n",
    "        'Banker': 9, 'Writer': 10, 'Accountant': 11, 'Designer': 12,\n",
    "        'Construction Engineer': 13, 'Game Developer': 14, 'Stock Investor': 15,\n",
    "        'Real Estate Developer': 16\n",
    "    }\n",
    "# Apply mapping to the DataFrame\n",
    "df['gender'] = df['gender'].map(gender_map)\n",
    "df['part_time_job'] = df['part_time_job'].map(part_time_job_map)\n",
    "df['extracurricular_activities'] = df['extracurricular_activities'].map(extracurricular_activities_map)\n",
    "df['career_aspiration'] = df['career_aspiration'].map(career_aspiration_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3338497-4669-4978-87ec-b9f54edec845",
   "metadata": {},
   "source": [
    "## Balance Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d38283ad-db8e-4d7c-98ba-fdb3983c89b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "career_aspiration\n",
       "5     315\n",
       "7     309\n",
       "4     223\n",
       "9     169\n",
       "0     138\n",
       "11    126\n",
       "1     119\n",
       "16     83\n",
       "15     73\n",
       "13     68\n",
       "3      67\n",
       "14     63\n",
       "2      61\n",
       "6      59\n",
       "12     56\n",
       "8      39\n",
       "10     32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['career_aspiration'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8ab3961-3c78-402b-95a4-dabdd5cf7e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Create SMOTE object\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('career_aspiration', axis=1)\n",
    "y = df['career_aspiration']\n",
    "\n",
    "# Apply SMOTE to the data\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba337e8-f5bb-4d3d-a80a-7a054f974a8b",
   "metadata": {},
   "source": [
    "## Train test split  80% data is for training and 20% data fro testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd38decc-8100-44bb-bcc9-47f07ad76fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4284, 14), (4284,), (1071, 14), (1071,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_resampled,y_resampled,test_size=0.2, random_state=42)\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d530d87-97d6-4ee0-a0fd-e99ee21098eb",
   "metadata": {},
   "source": [
    "## Feature Scalling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58169ffd-50e9-430a-9ebb-cd73bf90d9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform both training and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "719cf8e7-c83f-49e2-b6b6-73caeb25da21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4284, 14)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1488be5f-563d-4429-8428-59deb1880f77",
   "metadata": {},
   "source": [
    "## Models Training (Multiple Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e21274eb-c22c-4cf7-823c-6d666b06d9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.48739495798319327\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.54      0.49        68\n",
      "           1       0.49      0.62      0.55        72\n",
      "           2       0.42      0.44      0.43        57\n",
      "           3       0.52      0.57      0.55        58\n",
      "           4       0.31      0.17      0.22        66\n",
      "           5       0.32      0.32      0.32        76\n",
      "           6       0.58      0.92      0.71        71\n",
      "           7       0.83      0.90      0.87        61\n",
      "           8       0.41      0.45      0.43        53\n",
      "           9       0.29      0.10      0.15        61\n",
      "          10       0.59      0.71      0.65        63\n",
      "          11       0.44      0.45      0.45        53\n",
      "          12       0.31      0.16      0.21        68\n",
      "          13       0.38      0.49      0.43        55\n",
      "          14       0.61      0.93      0.74        57\n",
      "          15       0.37      0.24      0.29        63\n",
      "          16       0.55      0.32      0.40        69\n",
      "\n",
      "    accuracy                           0.49      1071\n",
      "   macro avg       0.46      0.49      0.46      1071\n",
      "weighted avg       0.46      0.49      0.46      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[37  4  0  0  0  7  0  0  4  1 10  3  0  2  0  0  0]\n",
      " [ 2 45  0  0  0  7  0  0 13  0  0  0  0  5  0  0  0]\n",
      " [ 0  0 25  5  1  1  9  1  0  0  2  0  4  1  2  2  4]\n",
      " [ 0  0  2 33  0  0  2  1  0  0  0  0  0  0 11  0  9]\n",
      " [ 6  5  7  3 11  9  7  1  2  3  0  3  3  2  1  2  1]\n",
      " [ 8  9  0  0  1 24  1  0  1  7  1  5  3 12  0  4  0]\n",
      " [ 0  0  0  0  1  2 65  0  0  1  2  0  0  0  0  0  0]\n",
      " [ 0  0  0  3  0  0  0 55  0  0  0  0  0  0  3  0  0]\n",
      " [ 4 18  0  0  0  1  0  0 24  0  6  0  0  0  0  0  0]\n",
      " [10  1  0  0  3  8  8  0  1  6  2  8  6  6  0  2  0]\n",
      " [ 8  2  0  0  1  0  4  0  2  1 45  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  4  6  3  0  4  1  0 24  1  3  0  6  0]\n",
      " [ 2  2  8  3  5  2  7  0  3  0  4  0 11  6  8  5  2]\n",
      " [ 1  2  2  0  3  0  0  0  5  1  1  4  4 27  0  5  0]\n",
      " [ 0  0  0  3  0  0  0  0  0  0  0  0  0  0 53  0  1]\n",
      " [ 4  3  3  0  5  8  1  2  0  0  2  7  4  7  1 15  1]\n",
      " [ 0  0 13 13  0  1  5  6  0  0  1  0  0  0  8  0 22]]\n",
      "==================================================\n",
      "Model: Support Vector Classifier\n",
      "Accuracy: 0.6470588235294118\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.62      0.58        68\n",
      "           1       0.60      0.83      0.70        72\n",
      "           2       0.60      0.74      0.66        57\n",
      "           3       0.69      0.86      0.77        58\n",
      "           4       0.55      0.18      0.27        66\n",
      "           5       0.41      0.32      0.36        76\n",
      "           6       0.70      0.93      0.80        71\n",
      "           7       0.86      0.93      0.90        61\n",
      "           8       0.65      0.81      0.72        53\n",
      "           9       0.38      0.33      0.35        61\n",
      "          10       0.84      0.86      0.85        63\n",
      "          11       0.82      0.51      0.63        53\n",
      "          12       0.65      0.51      0.57        68\n",
      "          13       0.53      0.85      0.65        55\n",
      "          14       0.77      0.93      0.84        57\n",
      "          15       0.67      0.44      0.53        63\n",
      "          16       0.77      0.48      0.59        69\n",
      "\n",
      "    accuracy                           0.65      1071\n",
      "   macro avg       0.65      0.66      0.63      1071\n",
      "weighted avg       0.65      0.65      0.63      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[42  6  0  0  0  4  0  0  2  4  6  0  0  3  0  1  0]\n",
      " [ 1 60  0  0  0  1  0  0  5  0  0  0  1  3  0  1  0]\n",
      " [ 0  0 42  2  2  1  4  0  0  0  0  0  2  0  0  3  1]\n",
      " [ 0  0  2 50  0  0  0  1  0  0  0  0  0  0  3  0  2]\n",
      " [ 5  8  7  1 12  7  5  2  1  7  0  2  4  3  1  1  0]\n",
      " [10  7  1  0  1 24  1  1  5 12  0  1  1 11  0  1  0]\n",
      " [ 0  0  0  0  0  1 66  0  0  2  1  0  0  0  0  0  1]\n",
      " [ 0  0  0  1  0  0  1 57  0  0  0  0  0  0  1  0  1]\n",
      " [ 1  8  0  0  0  1  0  0 43  0  0  0  0  0  0  0  0]\n",
      " [ 8  1  1  0  0  7  6  1  3 20  1  0  4  5  0  4  0]\n",
      " [ 2  1  4  0  0  0  0  0  0  1 54  0  0  1  0  0  0]\n",
      " [ 0  3  1  0  3  5  0  1  3  2  1 27  1  3  0  3  0]\n",
      " [ 2  1  0  3  2  1  8  0  2  0  1  1 35  4  4  0  4]\n",
      " [ 0  3  0  0  0  1  0  0  2  1  0  1  0 47  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  2  0  0  0  0  1  0 53  0  0]\n",
      " [ 5  2  3  0  2  4  0  0  0  3  0  1  4  9  1 28  1]\n",
      " [ 0  0  9 15  0  2  2  1  0  0  0  0  1  0  6  0 33]]\n",
      "==================================================\n",
      "Model: Random Forest Classifier\n",
      "Accuracy: 0.8328664799253035\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82        68\n",
      "           1       0.79      0.99      0.88        72\n",
      "           2       0.74      0.96      0.84        57\n",
      "           3       0.90      0.95      0.92        58\n",
      "           4       0.80      0.42      0.55        66\n",
      "           5       0.57      0.37      0.45        76\n",
      "           6       0.90      0.97      0.93        71\n",
      "           7       0.97      0.93      0.95        61\n",
      "           8       0.76      0.98      0.86        53\n",
      "           9       0.73      0.75      0.74        61\n",
      "          10       0.97      0.97      0.97        63\n",
      "          11       0.91      0.74      0.81        53\n",
      "          12       0.86      0.84      0.85        68\n",
      "          13       0.76      0.93      0.84        55\n",
      "          14       0.90      1.00      0.95        57\n",
      "          15       0.91      0.81      0.86        63\n",
      "          16       0.92      0.81      0.86        69\n",
      "\n",
      "    accuracy                           0.83      1071\n",
      "   macro avg       0.83      0.84      0.83      1071\n",
      "weighted avg       0.83      0.83      0.82      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[59  5  0  0  1  1  0  0  0  1  0  0  0  0  0  1  0]\n",
      " [ 0 71  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 55  0  0  0  1  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0 55  0  0  0  1  0  0  0  0  0  0  2  0  0]\n",
      " [ 4  3  7  0 28  8  1  0  2  3  1  2  4  0  1  0  2]\n",
      " [ 6  6  0  0  1 28  0  0  7 10  0  2  1 12  0  3  0]\n",
      " [ 0  0  0  0  0  1 69  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0 57  0  0  0  0  0  0  2  0  1]\n",
      " [ 0  1  0  0  0  0  0  0 52  0  0  0  0  0  0  0  0]\n",
      " [ 3  1  1  0  0  3  2  0  2 46  0  0  3  0  0  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  0 61  0  0  0  0  0  0]\n",
      " [ 0  3  0  0  2  5  1  0  1  1  0 39  0  1  0  0  0]\n",
      " [ 0  0  2  0  1  0  3  0  1  1  1  0 57  0  1  0  1]\n",
      " [ 0  0  2  0  0  0  0  0  1  0  0  0  0 51  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 57  0  0]\n",
      " [ 4  0  1  0  0  2  0  0  1  1  0  0  0  3  0 51  0]\n",
      " [ 0  0  6  5  0  0  0  1  1  0  0  0  0  0  0  0 56]]\n",
      "==================================================\n",
      "Model: K Nearest Neighbors\n",
      "Accuracy: 0.6778711484593838\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.68      0.63        68\n",
      "           1       0.73      0.78      0.75        72\n",
      "           2       0.63      0.86      0.73        57\n",
      "           3       0.60      0.81      0.69        58\n",
      "           4       0.35      0.17      0.23        66\n",
      "           5       0.35      0.14      0.21        76\n",
      "           6       0.83      0.92      0.87        71\n",
      "           7       0.90      0.72      0.80        61\n",
      "           8       0.67      0.91      0.77        53\n",
      "           9       0.44      0.48      0.46        61\n",
      "          10       0.81      0.92      0.86        63\n",
      "          11       0.71      0.64      0.67        53\n",
      "          12       0.71      0.79      0.75        68\n",
      "          13       0.69      0.80      0.74        55\n",
      "          14       0.82      0.89      0.86        57\n",
      "          15       0.65      0.62      0.63        63\n",
      "          16       0.78      0.58      0.67        69\n",
      "\n",
      "    accuracy                           0.68      1071\n",
      "   macro avg       0.66      0.69      0.67      1071\n",
      "weighted avg       0.66      0.68      0.66      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[46  2  0  0  0  3  0  0  1  8  6  0  0  0  0  2  0]\n",
      " [ 4 56  0  0  1  0  0  0  4  1  1  0  1  1  0  3  0]\n",
      " [ 0  0 49  1  0  0  0  0  0  0  2  0  0  0  1  1  3]\n",
      " [ 0  0  4 47  0  0  0  1  0  1  0  0  0  0  3  0  2]\n",
      " [ 4  5  5  5 11  6  6  1  2  7  1  1  6  1  1  1  3]\n",
      " [10  6  2  0  7 11  1  1  6  9  0  3  6 10  0  4  0]\n",
      " [ 0  0  1  2  0  0 65  0  0  2  0  0  0  0  1  0  0]\n",
      " [ 0  0  1  3  2  0  1 44  0  2  0  1  2  1  1  1  2]\n",
      " [ 1  4  0  0  0  0  0  0 48  0  0  0  0  0  0  0  0]\n",
      " [ 6  0  2  1  3  3  1  1  2 29  1  4  4  0  0  3  1]\n",
      " [ 2  0  2  0  0  0  0  0  0  1 58  0  0  0  0  0  0]\n",
      " [ 0  2  2  0  0  5  0  0  3  2  1 34  1  2  1  0  0]\n",
      " [ 1  1  2  2  0  0  1  0  0  2  1  1 54  0  0  3  0]\n",
      " [ 2  0  0  0  4  0  0  0  3  0  0  0  0 44  1  1  0]\n",
      " [ 0  0  1  1  0  1  0  0  0  0  0  0  1  1 51  1  0]\n",
      " [ 2  1  1  4  2  1  1  0  3  2  0  4  0  3  0 39  0]\n",
      " [ 0  0  6 12  1  1  2  1  0  0  1  0  1  1  2  1 40]]\n",
      "==================================================\n",
      "Model: Decision Tree Classifier\n",
      "Accuracy: 0.6816059757236228\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.60      0.59        68\n",
      "           1       0.76      0.90      0.83        72\n",
      "           2       0.68      0.68      0.68        57\n",
      "           3       0.87      0.78      0.82        58\n",
      "           4       0.41      0.42      0.41        66\n",
      "           5       0.42      0.26      0.32        76\n",
      "           6       0.84      0.82      0.83        71\n",
      "           7       0.96      0.77      0.85        61\n",
      "           8       0.86      0.92      0.89        53\n",
      "           9       0.52      0.54      0.53        61\n",
      "          10       0.77      0.84      0.80        63\n",
      "          11       0.60      0.60      0.60        53\n",
      "          12       0.64      0.68      0.66        68\n",
      "          13       0.60      0.71      0.65        55\n",
      "          14       0.80      0.91      0.85        57\n",
      "          15       0.57      0.49      0.53        63\n",
      "          16       0.73      0.75      0.74        69\n",
      "\n",
      "    accuracy                           0.68      1071\n",
      "   macro avg       0.68      0.69      0.68      1071\n",
      "weighted avg       0.68      0.68      0.68      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[41  3  0  0  2 10  0  0  0  1  5  0  1  4  0  1  0]\n",
      " [ 2 65  0  0  0  0  0  0  1  0  0  1  1  0  0  2  0]\n",
      " [ 0  0 39  0  2  0  1  1  0  4  0  0  4  1  0  2  3]\n",
      " [ 0  0  0 45  2  0  0  0  0  0  0  0  1  0  5  0  5]\n",
      " [ 4  3  6  0 28  3  1  0  1  4  2  2  3  1  1  2  5]\n",
      " [ 8  7  0  0  8 20  1  0  3  8  3  6  3  5  0  4  0]\n",
      " [ 0  0  2  0  3  2 58  0  0  3  1  0  2  0  0  0  0]\n",
      " [ 0  0  0  1  4  0  0 47  0  0  0  0  1  0  5  0  3]\n",
      " [ 1  1  0  0  0  0  0  0 49  1  1  0  0  0  0  0  0]\n",
      " [ 7  0  0  0  2  3  3  0  0 33  2  5  1  1  0  3  1]\n",
      " [ 0  1  0  0  1  0  0  0  1  3 53  0  1  2  0  1  0]\n",
      " [ 2  2  0  0  3  1  2  0  2  2  1 32  5  0  0  1  0]\n",
      " [ 0  1  0  1  6  1  1  0  0  1  1  1 46  3  1  4  1]\n",
      " [ 6  1  1  0  1  0  0  0  0  3  0  2  1 39  0  1  0]\n",
      " [ 0  0  0  1  1  0  0  0  0  0  0  0  2  0 52  0  1]\n",
      " [ 1  1  5  0  5  7  0  0  0  0  0  4  0  9  0 31  0]\n",
      " [ 0  0  4  4  1  1  2  1  0  1  0  0  0  0  1  2 52]]\n",
      "==================================================\n",
      "Model: Gaussian Naive Bayes\n",
      "Accuracy: 0.3099906629318394\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.22      0.32        68\n",
      "           1       0.64      0.53      0.58        72\n",
      "           2       0.18      0.05      0.08        57\n",
      "           3       0.30      0.05      0.09        58\n",
      "           4       0.50      0.06      0.11        66\n",
      "           5       0.45      0.18      0.26        76\n",
      "           6       0.31      1.00      0.47        71\n",
      "           7       0.95      0.85      0.90        61\n",
      "           8       0.64      0.17      0.27        53\n",
      "           9       0.20      0.03      0.06        61\n",
      "          10       0.69      0.35      0.46        63\n",
      "          11       0.60      0.23      0.33        53\n",
      "          12       0.50      0.13      0.21        68\n",
      "          13       0.11      0.96      0.20        55\n",
      "          14       0.00      0.00      0.00        57\n",
      "          15       0.50      0.06      0.11        63\n",
      "          16       0.47      0.30      0.37        69\n",
      "\n",
      "    accuracy                           0.31      1071\n",
      "   macro avg       0.45      0.31      0.28      1071\n",
      "weighted avg       0.45      0.31      0.29      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[15  0  0  0  0  3  4  0  1  0  4  2  0 39  0  0  0]\n",
      " [ 0 38  0  0  0  2  3  0  3  0  0  0  2 24  0  0  0]\n",
      " [ 0  0  3  0  1  1 16  0  0  0  0  0  0 31  0  2  3]\n",
      " [ 0  0  0  3  0  0 15  1  0  0  0  0  0 23  3  0 13]\n",
      " [ 3  3  0  3  4  3 13  0  0  2  0  3  3 26  0  0  3]\n",
      " [ 4  6  0  0  1 14 12  0  0  2  0  1  1 34  0  1  0]\n",
      " [ 0  0  0  0  0  0 71  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  3 52  0  0  0  0  0  3  0  0  2]\n",
      " [ 0  3  0  0  0  0  0  0  9  1  1  0  0 39  0  0  0]\n",
      " [ 2  1  1  0  1  2 16  0  0  2  4  1  1 30  0  0  0]\n",
      " [ 3  6  0  0  0  0  9  0  0  1 22  0  0 22  0  0  0]\n",
      " [ 0  0  0  0  0  1 13  0  0  0  0 12  1 25  0  1  0]\n",
      " [ 0  1  7  0  0  0 21  0  1  0  1  0  9 27  0  0  1]\n",
      " [ 0  1  0  0  0  1  0  0  0  0  0  0  0 53  0  0  0]\n",
      " [ 0  0  0  0  0  0 11  1  0  0  0  0  0 45  0  0  0]\n",
      " [ 0  0  1  0  1  2  6  0  0  1  0  1  1 44  0  4  2]\n",
      " [ 0  0  5  3  0  2 16  1  0  1  0  0  0 20  0  0 21]]\n",
      "==================================================\n",
      "Model: AdaBoost Classifier\n",
      "Accuracy: 0.2334267040149393\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        68\n",
      "           1       1.00      0.61      0.76        72\n",
      "           2       0.28      0.56      0.37        57\n",
      "           3       0.00      0.00      0.00        58\n",
      "           4       0.00      0.00      0.00        66\n",
      "           5       0.00      0.00      0.00        76\n",
      "           6       0.29      0.79      0.42        71\n",
      "           7       0.00      0.00      0.00        61\n",
      "           8       0.15      1.00      0.27        53\n",
      "           9       0.00      0.00      0.00        61\n",
      "          10       0.18      0.38      0.25        63\n",
      "          11       0.00      0.00      0.00        53\n",
      "          12       0.00      0.00      0.00        68\n",
      "          13       0.00      0.00      0.00        55\n",
      "          14       0.00      0.00      0.00        57\n",
      "          15       0.00      0.00      0.00        63\n",
      "          16       0.17      0.59      0.27        69\n",
      "\n",
      "    accuracy                           0.23      1071\n",
      "   macro avg       0.12      0.23      0.14      1071\n",
      "weighted avg       0.13      0.23      0.14      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 0  0  0  0  0  0  0  0 68  0  0  0  0  0  0  0  0]\n",
      " [ 0 44  0  0  0  0  0  0 20  0  8  0  0  0  0  0  0]\n",
      " [ 0  0 32  0  0  0 15  0  0  0  0  0  0  0  0  0 10]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 58]\n",
      " [ 0  0 14  0  0  0  9  0 27  0 11  0  0  0  0  0  5]\n",
      " [ 0  0  0  0  0  0 10  0 45  0 21  0  0  0  0  0  0]\n",
      " [ 0  0 14  0  0  0 56  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 61]\n",
      " [ 0  0  0  0  0  0  0  0 53  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  3  0  0  0 18  0 24  0 16  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  8  0 31  0 24  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 15  0 22  0 16  0  0  0  0  0  0]\n",
      " [ 0  0 16  0  0  0 24  0 12  0  8  0  0  0  0  0  8]\n",
      " [ 0  0  1  0  0  0 25  0 14  0 15  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 57]\n",
      " [ 0  0  8  0  0  0 15  0 28  0 12  0  0  0  0  0  0]\n",
      " [ 0  0 28  0  0  0  0  0  0  0  0  0  0  0  0  0 41]]\n",
      "==================================================\n",
      "Model: Gradient Boosting Classifier\n",
      "Accuracy: 0.7469654528478058\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.79      0.73        68\n",
      "           1       0.80      0.97      0.88        72\n",
      "           2       0.63      0.88      0.74        57\n",
      "           3       0.81      0.90      0.85        58\n",
      "           4       0.48      0.17      0.25        66\n",
      "           5       0.49      0.45      0.47        76\n",
      "           6       0.85      0.99      0.92        71\n",
      "           7       0.97      0.95      0.96        61\n",
      "           8       0.78      1.00      0.88        53\n",
      "           9       0.49      0.44      0.47        61\n",
      "          10       0.90      0.95      0.92        63\n",
      "          11       0.80      0.62      0.70        53\n",
      "          12       0.76      0.60      0.67        68\n",
      "          13       0.66      0.87      0.75        55\n",
      "          14       0.89      0.98      0.93        57\n",
      "          15       0.75      0.57      0.65        63\n",
      "          16       0.82      0.68      0.75        69\n",
      "\n",
      "    accuracy                           0.75      1071\n",
      "   macro avg       0.74      0.75      0.74      1071\n",
      "weighted avg       0.74      0.75      0.73      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[54  4  0  0  2  5  0  0  0  1  0  2  0  0  0  0  0]\n",
      " [ 1 70  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0 50  1  0  1  3  0  0  0  0  0  0  0  0  0  2]\n",
      " [ 0  0  0 52  0  0  0  1  0  0  0  0  1  0  2  0  2]\n",
      " [ 5  4 11  0 11 10  1  0  1  8  2  1  3  3  1  3  2]\n",
      " [ 7  3  0  0  2 34  0  0  3 11  0  1  0 12  0  3  0]\n",
      " [ 0  0  0  0  1  0 70  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0 58  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 53  0  0  0  0  0  0  0  0]\n",
      " [ 5  0  3  0  2  5  3  0  4 27  3  0  4  1  0  4  0]\n",
      " [ 2  1  0  0  0  0  0  0  0  0 60  0  0  0  0  0  0]\n",
      " [ 1  3  1  0  1  3  2  0  3  4  0 33  0  2  0  0  0]\n",
      " [ 1  0  5  1  1  3  1  0  1  3  1  1 41  2  2  2  3]\n",
      " [ 1  1  2  0  0  1  0  0  2  0  0  0  0 48  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0 56  0  0]\n",
      " [ 3  2  2  0  1  7  0  0  1  1  1  3  1  4  0 36  1]\n",
      " [ 0  0  5  8  2  0  2  1  0  0  0  0  3  0  1  0 47]]\n",
      "==================================================\n",
      "Model: XGBoost Classifier\n",
      "Accuracy: 0.8272642390289449\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.82        68\n",
      "           1       0.83      0.94      0.88        72\n",
      "           2       0.81      0.91      0.86        57\n",
      "           3       0.87      0.91      0.89        58\n",
      "           4       0.88      0.42      0.57        66\n",
      "           5       0.55      0.42      0.48        76\n",
      "           6       0.92      0.97      0.95        71\n",
      "           7       0.95      0.93      0.94        61\n",
      "           8       0.84      1.00      0.91        53\n",
      "           9       0.61      0.70      0.66        61\n",
      "          10       0.98      0.97      0.98        63\n",
      "          11       0.75      0.72      0.73        53\n",
      "          12       0.91      0.93      0.92        68\n",
      "          13       0.75      0.91      0.82        55\n",
      "          14       0.92      0.98      0.95        57\n",
      "          15       0.78      0.71      0.74        63\n",
      "          16       0.94      0.87      0.90        69\n",
      "\n",
      "    accuracy                           0.83      1071\n",
      "   macro avg       0.83      0.83      0.82      1071\n",
      "weighted avg       0.83      0.83      0.82      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[58  3  0  0  2  1  0  0  0  1  0  1  0  1  0  1  0]\n",
      " [ 1 68  0  0  0  0  0  0  1  1  0  0  1  0  0  0  0]\n",
      " [ 0  0 52  0  0  1  1  0  0  1  0  0  1  0  0  0  1]\n",
      " [ 0  0  0 53  0  0  0  1  0  0  0  0  0  0  2  0  2]\n",
      " [ 4  3  6  0 28  9  2  0  2  6  1  0  2  0  1  2  0]\n",
      " [ 8  4  0  0  0 32  0  0  2 10  0  4  0 11  0  5  0]\n",
      " [ 0  0  0  0  0  0 69  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  3  0  0  0 57  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0 53  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  2  0  0  4  1  0  2 43  0  3  2  0  0  3  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0 61  0  0  1  0  0  0]\n",
      " [ 1  2  0  0  0  4  2  0  2  3  0 38  0  1  0  0  0]\n",
      " [ 0  1  1  0  0  0  0  0  0  0  0  1 63  0  2  0  0]\n",
      " [ 0  0  1  0  0  2  0  0  0  0  0  0  0 50  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0 56  0  0]\n",
      " [ 1  1  0  0  1  5  0  0  0  3  0  4  0  3  0 45  0]\n",
      " [ 0  0  2  5  1  0  0  1  0  0  0  0  0  0  0  0 60]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "    \"K Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "    \"XGBoost Classifier\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(\"=\"*50)\n",
    "    print(\"Model:\", name)\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", classification_rep)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e18cd59-bd3d-4e1b-a154-71dcd8bdb3fe",
   "metadata": {},
   "source": [
    "## Model Selection (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51adae0e-2be9-4aff-bbb4-19cdf431d0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8281979458450047\n",
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83        68\n",
      "           1       0.80      1.00      0.89        72\n",
      "           2       0.75      0.95      0.84        57\n",
      "           3       0.87      0.95      0.91        58\n",
      "           4       0.83      0.44      0.57        66\n",
      "           5       0.57      0.33      0.42        76\n",
      "           6       0.91      1.00      0.95        71\n",
      "           7       0.95      0.93      0.94        61\n",
      "           8       0.74      0.98      0.85        53\n",
      "           9       0.69      0.70      0.70        61\n",
      "          10       0.90      0.98      0.94        63\n",
      "          11       0.89      0.74      0.80        53\n",
      "          12       0.89      0.87      0.88        68\n",
      "          13       0.77      0.91      0.83        55\n",
      "          14       0.89      0.98      0.93        57\n",
      "          15       0.92      0.78      0.84        63\n",
      "          16       0.89      0.78      0.83        69\n",
      "\n",
      "    accuracy                           0.83      1071\n",
      "   macro avg       0.83      0.84      0.82      1071\n",
      "weighted avg       0.82      0.83      0.82      1071\n",
      "\n",
      "Confusion Matrix:  [[60  5  0  0  1  0  0  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0 72  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 54  0  0  0  1  0  0  0  0  0  0  0  0  0  2]\n",
      " [ 0  0  0 55  0  0  0  1  0  0  0  0  0  0  2  0  0]\n",
      " [ 4  2  8  0 29  8  0  0  4  3  1  0  2  0  1  1  3]\n",
      " [ 8  4  0  0  2 25  1  0  6 12  1  3  1 12  0  1  0]\n",
      " [ 0  0  0  0  0  0 71  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0 57  0  0  0  0  0  0  2  0  1]\n",
      " [ 0  1  0  0  0  0  0  0 52  0  0  0  0  0  0  0  0]\n",
      " [ 2  1  0  0  0  3  3  0  2 43  3  0  4  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0 62  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  1  4  0  0  2  2  1 39  0  1  0  1  0]\n",
      " [ 0  0  2  0  1  1  1  0  1  0  1  0 59  0  1  0  1]\n",
      " [ 0  0  2  0  0  0  0  0  2  0  0  0  0 50  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0 56  0  0]\n",
      " [ 2  3  2  0  1  2  0  0  0  0  0  2  0  2  0 49  0]\n",
      " [ 0  0  3  7  0  1  1  1  1  0  0  0  0  0  1  0 54]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "print(\"Report: \",classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \",confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bda3ee-92bd-4ff9-970b-fdc3fc7d6d1b",
   "metadata": {},
   "source": [
    "## Single Input Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5712ecee-4310-4d2f-a787-6ebbc7103cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label : 12\n",
      "Model Prediction : 12\n",
      "Wow! Model doing well.....\n"
     ]
    }
   ],
   "source": [
    "# test 1\n",
    "print(\"Actual Label :\", y_test.iloc[10])\n",
    "print(\"Model Prediction :\",model.predict(X_test_scaled[10].reshape(1,-1))[0])\n",
    "if y_test.iloc[10]==model.predict(X_test_scaled[10].reshape(1,-1)):\n",
    "    print(\"Wow! Model doing well.....\")\n",
    "else:\n",
    "    print(\"not sure......\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "270e2be4-6952-4951-a503-7af3e70ca395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label : 0\n",
      "Model Prediction : 0\n",
      "Wow! Model doing well.....\n"
     ]
    }
   ],
   "source": [
    "# test 2\n",
    "print(\"Actual Label :\", y_test.iloc[300])\n",
    "print(\"Model Prediction :\",model.predict(X_test_scaled[300].reshape(1,-1))[0])\n",
    "if y_test.iloc[10]==model.predict(X_test_scaled[10].reshape(1,-1)):\n",
    "    print(\"Wow! Model doing well.....\")\n",
    "else:\n",
    "    print(\"not sure......\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3624f5-01d9-4735-85ae-ab028494d8b0",
   "metadata": {},
   "source": [
    "## Saving & Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e7b916d-298a-4192-bc1d-b12de0d5b59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# SAVE FILES\n",
    "pickle.dump(scaler,open(\"Models/scaler.pkl\",'wb'))\n",
    "pickle.dump(model,open(\"Models/model.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6edb6483-eca5-4553-bdf4-39e9ceea811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the scaler, label encoder, and model\n",
    "scaler = pickle.load(open(\"Models/scaler.pkl\", 'rb'))\n",
    "model = pickle.load(open(\"Models/model.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f41db20-5d88-40f8-8b5e-973236905aac",
   "metadata": {},
   "source": [
    "## Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "708f2ac1-1d68-42b5-89e9-c4e7026cbdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the scaler, label encoder, model, and class names\n",
    "scaler = pickle.load(open(\"Models/scaler.pkl\", 'rb'))\n",
    "model = pickle.load(open(\"Models/model.pkl\", 'rb'))\n",
    "class_names = ['Lawyer', 'Doctor', 'Government Officer', 'Artist', 'Machanical Engineer',\n",
    "               'Software Engineer', 'Teacher', 'Business Owner', 'Scientist',\n",
    "               'Banker', 'Writer', 'Accountant', 'Designer',\n",
    "               'Construction Engineer', 'Game Developer', 'Stock Investor',\n",
    "               'Real Estate Developer']\n",
    "\n",
    "def Recommendations(gender, part_time_job, absence_days, extracurricular_activities,\n",
    "                    weekly_self_study_hours, math_score, history_score, physics_score,\n",
    "                    chemistry_score, biology_score, english_score, geography_score,\n",
    "                    total_score,average_score):\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    gender_encoded = 1 if gender.lower() == 'female' else 0\n",
    "    part_time_job_encoded = 1 if part_time_job else 0\n",
    "    extracurricular_activities_encoded = 1 if extracurricular_activities else 0\n",
    "        \n",
    "    # Create feature array\n",
    "    feature_array = np.array([[gender_encoded, part_time_job_encoded, absence_days, extracurricular_activities_encoded,\n",
    "                               weekly_self_study_hours, math_score, history_score, physics_score,\n",
    "                               chemistry_score, biology_score, english_score, geography_score,total_score,average_score]])\n",
    "    \n",
    "    # Scale features\n",
    "    scaled_features = scaler.transform(feature_array)\n",
    "    \n",
    "    # Predict using the model\n",
    "    probabilities = model.predict_proba(scaled_features)\n",
    "    \n",
    "    # Get top five predicted classes along with their probabilities\n",
    "    top_classes_idx = np.argsort(-probabilities[0])[:5]\n",
    "    top_classes_names_probs = [(class_names[idx], probabilities[0][idx]) for idx in top_classes_idx]\n",
    "    \n",
    "    return top_classes_names_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "17a7f8f4-c6a6-43c0-bf87-bc7e3ecb1964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended studies with probabilities:\n",
      "==================================================\n",
      "Teacher with probability 0.9672384858131409\n",
      "Mechanical Engineer with probability 0.02495722286403179\n",
      "Real Estate Developer with probability 0.0035242345184087753\n",
      "Government Officer with probability 0.0026798704639077187\n",
      "Designer with probability 0.000667896238155663\n"
     ]
    }
   ],
   "source": [
    "# Example usage 1\n",
    "final_recommendations = Recommendations(gender='female',\n",
    "                                        part_time_job=False,\n",
    "                                        absence_days=2,\n",
    "                                        extracurricular_activities=False,\n",
    "                                        weekly_self_study_hours=7,\n",
    "                                        math_score=65,\n",
    "                                        history_score=60,\n",
    "                                        physics_score=97,\n",
    "                                        chemistry_score=94,\n",
    "                                        biology_score=71,\n",
    "                                        english_score=81,\n",
    "                                        geography_score=66,\n",
    "                                        total_score=534,\n",
    "                                        average_score=76.285714)\n",
    "\n",
    "print(\"Top recommended studies with probabilities:\")\n",
    "print(\"=\"*50)\n",
    "for class_name, probability in final_recommendations:\n",
    "    print(f\"{class_name} with probability {probability}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d70e6ce7-c447-4bd5-83fd-5600639e226e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommended studies with probabilities:\n",
      "==================================================\n",
      "Artist with probability 0.51\n",
      "Game Developer with probability 0.33\n",
      "Real Estate Developer with probability 0.09\n",
      "Construction Engineer with probability 0.02\n",
      "Designer with probability 0.02\n"
     ]
    }
   ],
   "source": [
    "# Example usage 2\n",
    "final_recommendations = Recommendations(gender='female',\n",
    "                                        part_time_job=False,\n",
    "                                        absence_days=2,\n",
    "                                        extracurricular_activities=False,\n",
    "                                        weekly_self_study_hours=4,\n",
    "                                        math_score=87,\n",
    "                                        history_score=73,\n",
    "                                        physics_score=98,\n",
    "                                        chemistry_score=91,\n",
    "                                        biology_score=79,\n",
    "                                        english_score=60,\n",
    "                                        geography_score=77,\n",
    "                                        total_score=583,\n",
    "                                        average_score=83.285714)\n",
    "\n",
    "print(\"Top recommended studies with probabilities:\")\n",
    "print(\"=\"*50)\n",
    "for class_name, probability in final_recommendations:\n",
    "    print(f\"{class_name} with probability {probability}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c8fd8-cd1b-42ad-ae89-957e33f5e750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951eb80f-636d-4fc3-a517-62565db401ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
